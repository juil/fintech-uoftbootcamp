# Unit 12 Notes
### Supervised Learning

## Logistic Regression

### Classification Report 

The classification report generated by imblearn's metrics module provides information about the precision, recall, F1-score, and support for each class in a classification problem. Here's how you can read it:

- Precision: It indicates how many of the samples predicted as a particular class are actually labeled as that class. It is calculated as the ratio of true positives to the sum of true positives and false positives. A high precision score indicates a low number of false positives.

- Recall: It shows how well the classifier can identify all the positive samples. It is calculated as the ratio of true positives to the sum of true positives and false negatives. A high recall score indicates a low number of false negatives.

- F1-score: It is the harmonic mean of precision and recall and provides a single score that combines both metrics. It ranges from 0 to 1, where 1 is the best possible score.

- Support: It is the number of samples in each class.

- The "iba" column in the classification report stands for "index balanced accuracy". The index balanced accuracy is a metric used to evaluate the performance of a machine learning algorithm on imbalanced datasets. It is a modification of the balanced accuracy score that takes into account the imbalance in the class distribution.

The balanced accuracy score is calculated as the arithmetic mean of the recall (sensitivity) of each class. However, in imbalanced datasets, the balanced accuracy may be dominated by the majority class, leading to a false sense of model performance.

The index balanced accuracy addresses this issue by giving more weight to the minority class. It is calculated based on the geometric mean of the recall of each class, with the weights inversely proportional to the class frequency.

A higher iba score indicates that the model has a better balance between the recall scores for each class, particularly considering the class imbalance problem.

The classification report will display these metrics for each class in the target variable. So, for binary classification, the report will have two rows, one for each class. For multi-class classification, there will be a row for each class, and the metrics will be calculated by considering that class as the positive class and the rest as negative classes.
